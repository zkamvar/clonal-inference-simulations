---
title: "Assessing bias due to reduced sample size"
output:
  html_document: default
---

## Introduction

We've shown that clone-correction can reduce the power of $\bar{r}_d$ to detect
clonal reproduction, but it's also clear that a reduced sample size contributes
to this as well. To disentangle this, we assess the $\bar{r}_d$ from 1000 
replicates of *n* samples where *n* is the size of the data set after 
clone-correction. The data were processed via the `analyze_jackknife_ia.R`
script. These were saved in the `ma_jack_rda_files/` directory.

> Note: this is the same analysis, utilizing more simulated alleles.

## Setup


### Packages

```{r, required_packages}
library('zksimanalysis')
```

### Loading Data

```{r}
res        <- load("../data/ma_full_results.rda") # load original values of rd
jack_files <- list.files("../data/ma_jack_rda_files/", full.names = TRUE) # load jackknife simulations
jacklist   <- setNames(jack_files, basename(jack_files))

for (i in jack_files){
  jacklist[basename(i)] <- load(i)
}
jackdat <- jacklist %>% 
  map_df(get, .id = "source") %>% 
  mutate(mutation_rate = ifelse(grepl("mutant", source), "even", "uneven")) %>%
  mutate(source = gsub("(^.+?feather).*$", "\\1.DATA.rda", source)) %>%
  select(matches("jack"), everything())
rm(list = jacklist)
gc()

# taking stock of how much data we have
jackdat %>% filter(!is.na(pop))
get(res)
```

Note that above, I'm filtering `jackdat` for non-missing populations. I should
explain this a bit. When `jack.ia` was put into *poppr*, the requirements for
running that **n** was greater than 2 and smaller than the total popualtion size.
If the number of MLGs did not fit this requirement, `tidy_jackia` would  return 
all `NA`, including that for population. 

We can't ask any questions regarding bias with missing data, so we are filtering
it out here.

```{r}
# combining original values and jackknife simulations
vals <- get(res) %>%
  inner_join(filter(jackdat, !is.na(pop)), # filtering out missing data
             by = c("source", "mutation_rate", "pop")) %>%
  select(rbarD, jack.rd, jack.p.rD, mutation_rate, everything())
vals
```

## Data Exploring!

First, let's see what we have after the filtering:

```{r}
vals %>%
  group_by(mutation_rate, sexrate, sample) %>%
  summarize(n = n()) %>%
  spread(sample, n) %>%
  knitr::kable()
```

Now, let's visualize the "p-value" for each jack knife analysis. This p-value
represents the fraction of jack-knife simulations less than or equal to the 
clone-corrected value. 

In essence, we are asking the following question:

> Can the clone-corrected value of $\bar{r}_d$ be attributed to a small sample
> size?

```{r pval, fig.width = 7, fig.height = 10}
vals %>%
  ggplot(aes(x = jack.p.rD, group = mutation_rate, fill = mutation_rate)) +
  geom_histogram(alpha = 0.5, binwidth = 0.05) +
  facet_grid(sexrate~sample, scales = "free")
```

Let's take a look at the values when the pvalue for $\bar{r}_d$ is < 0.05:

```{r pval-sig, fig.width = 7, fig.height = 7}
vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sprintf("%.2f (%d)", sum(jack.p.rD < 0.05)/n(), n())) %>%
  spread(sample, reject)
vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  ggplot(aes(x = jack.p.rD, group = mutation_rate, fill = mutation_rate)) +
  geom_histogram(alpha = 0.5, binwidth = 0.05) +
  facet_grid(sexrate~sample, scales = "free_y")
```

Yeah, those don't look too good. The graph above is basically saying that we
would consider most of the clonal populations to be sexually derived because the
clone-corrected value is lower than the distribution. Of course, this is 
expecting that the mean value for the distribution is near the observed value of
the whole data set. This may not be true.

To correct for this, I'm going to calculate the bias a la Section 10.3 in Efron 
and Tibshirani by subtracting the observed value from the bootstrap estimate:

$$
\hat\theta_B = \frac{1}{B} \sum\theta^*\\
Bias[\hat\theta] = \hat\theta_B - \hat\theta
$$

Once I have the bias, I'm going to compare the bias-corrected value of the
clone-corrected $\bar{r}_d$ to the null distribution of the full data set. This
would allow us to see if the reduced sample size affected the data (good example
from <http://www.stat.umn.edu/geyer/5601/examp/bias.html>).


> Note to future Zhian:
> 
> The answer may not be as simple as accounting for bias due to sample size, but
> also bias due to duplicated samples. Perhaps the way to go is to subtract the
> sum of the biases from the data. 

```{r pvals-bias, fig.height = 7, fig.width = 7}
makep <- function(x, y) (sum(x <= y, na.rm = TRUE) + 1)/(length(y) + 1)
bvals <- vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  mutate(jack.mean = map_dbl(jack.rd, mean, na.rm = TRUE)) %>%
  mutate(bias = jack.mean - rbarD) %>% # calculating bias a la Effron
  select(bias, jack.mean, everything()) %>%
  mutate(jack.p.rDb = map2_dbl(rbarDcc - bias, samples.rd, makep)) %>%
  select(bias, jack.p.rD, jack.p.rDb, everything())
```

Now we can visualize this as a table of the percentage rejection.

```{r}
bvals %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sprintf("%.2f (%.4f)", 
                             sum(jack.p.rDb < 0.05)/n(), 
                             median(bias, na.rm = TRUE))) %>%
  spread(sample, reject) %>%
  knitr::kable(digits = 3, caption = "Null Hypothesis Rejected (median bias)")
```


```{r, fig.width = 10, fig.height = 7}
bvals %>%
  ggplot(aes(x = p.rDcc, group = mutation_rate, fill = mutation_rate)) +
  geom_density(alpha = 0.75) +
  geom_rug(alpha = 0.5) +
  facet_grid(sexrate~sample, scales = "free_y") +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  ggtitle("Clone-censored p-values without bias correction") +
  xlab("P-value")


bvals %>%
  ggplot(aes(x = jack.p.rDb, group = mutation_rate, fill = mutation_rate)) +
  geom_density(alpha = 0.75) +
  geom_rug(alpha = 0.5) +
  facet_grid(sexrate~sample, scales = "free_y") +
  scale_fill_viridis(option = "D", discrete = TRUE) +
  ggtitle("P-values after bias correction of clone-censored data") +
  xlab("P-value (bias-corrected)")


bvals %>%
  unite(the_group, seed, rep, run, gen) %>%
  ggplot(aes(x = sexrate, y = bias, fill = mutation_rate)) +
  geom_line(aes(group = the_group), alpha = 0.2) +
  geom_boxplot(aes(group = factor(sexrate))) +
  # geom_point(aes(group = the_group), alpha = 0.2) +
  facet_grid(sample ~ mutation_rate)
```

Well, it turns out that things got worse, folks. Perhaps the answer is that we 
need to consider the fact that there is over-representation of the clones. If we
parameterize the resampling procedure by weighting the samples by the value of 
$p_{sex}$, then we can account for this over-representation. Consider that it is
possible for a clonal genotype to be identical in state without being identical 
by descent. This is roughly what $p_{sex}$ measures. When we weight the
resamplings with $p_{sex}$, it's more likely for us to grab a smaller population
that's representative of what the underlying genotypes are. We can use that to
calculate the bias due to smaller sample size and use that to correct the
clone-corrected estimate.

# Assessing jackknife analysis weighted by $p_{sex}$

I went back and created new analyses, weighted by $p_{sex}$. To avoid wasting
memory, I'm going to remove the unnecessary data we have thus far:

```{r, tidy_up}
rm(vals, jackdat)
gc()
```

Now, I can load in the new results:

```{r, jack_psex}
jack_files <- list.files("../data/ma_jack_psex_rda_files/", full.names = TRUE) # load jackknife simulations
jacklist   <- setNames(jack_files, basename(jack_files))

for (i in jack_files){
  jacklist[basename(i)] <- load(i)
}
jackdat <- jacklist %>% 
  map_df(get, .id = "source") %>% 
  mutate(mutation_rate = ifelse(grepl("mutant", source), "even", "uneven")) %>%
  mutate(source = gsub("(^.+?feather).*$", "\\1.DATA.rda", source)) %>%
  select(matches("jack"), everything())
rm(list = jacklist)
gc()

# taking stock of how much data we have
jackdat %>% filter(!is.na(pop))
```

```{r}
# combining original values and jackknife simulations
vals <- get(res) %>%
  inner_join(filter(jackdat, !is.na(pop)), # filtering out missing data
             by = c("source", "mutation_rate", "pop")) %>%
  select(rbarD, jack.rd, jack.p.rD, mutation_rate, everything())
vals
```

```{r}
vals %>%
  group_by(mutation_rate, sexrate, sample) %>%
  summarize(n = n()) %>%
  spread(sample, n) %>%
  knitr::kable()
```

```{r pval_psex, fig.width = 7, fig.height = 10}
vals %>%
  ggplot(aes(x = jack.p.rD, group = mutation_rate, fill = mutation_rate)) +
  geom_histogram(alpha = 0.5, binwidth = 0.05) +
  facet_grid(sexrate~sample, scales = "free") +
  ggtitle("P-value from jack-knife analysis weighted by psex")
```

Okay this result is almost the complete opposite as compared to the one above.
Let's take a look at the values when the pvalue for $\bar{r}_d$ is < 0.05:

```{r pval-psex-sig, fig.width = 7, fig.height = 7}
vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sprintf("%.2f (%d)", sum(jack.p.rD < 0.05)/n(), n())) %>%
  spread(sample, reject)
vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  ggplot(aes(x = jack.p.rD, group = mutation_rate, fill = mutation_rate)) +
  geom_histogram(alpha = 0.5, binwidth = 0.05) +
  facet_grid(sexrate~sample, scales = "free_y")
```

## Bias correction


```{r pvals-psex-bias, fig.height = 7, fig.width = 7}
makep <- function(x, y) (sum(x <= y, na.rm = TRUE) + 1)/(length(y) + 1)
bvals <- vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  mutate(jack.mean = map_dbl(jack.rd, mean, na.rm = TRUE)) %>%
  mutate(bias = jack.mean - rbarD) %>% # calculating bias a la Effron
  select(bias, jack.mean, everything()) %>%
  mutate(jack.p.rDb = map2_dbl(rbarDcc - bias, samples.rdcc, makep)) %>%
  select(bias, jack.p.rD, jack.p.rDb, everything())
```


Now we can visualize this as a table of the percentage rejection.

```{r}
bvals %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sprintf("%.2f (%.4f)", 
                             sum(jack.p.rDb < 0.01)/n(), 
                             mean(bias[is.finite(bias)], na.rm = TRUE))) %>%
  spread(sample, reject) %>%
  knitr::kable(digits = 3, caption = "Null Hypothesis Rejected (median bias)")
```




Now this is showing promise. To recap, this table is derived from the situations
in which $\bar{r}_d$ was significant for the full data set, but not for the 
clone-corrected data set. The values represented are the fraction of 
clone-corrected populations that rejected the null hypothesis after 
bias-correction.

A couple of notes about this table. I had to specify finite values for the bias
because for sexrates less than 0.0005 and a sample size of 10, we saw some
levels of bias less than -1, and a couple that were infinite. I'll plot them
here for your enjoyment.

```{r}
infbias <- bvals %>% filter(bias < -1) %>% 
  select(pop, jack.rd, rbarDcc, NMLG)
infbias %>%
  unnest() %>%
  ggplot(aes(x = jack.rd)) +
  geom_density(aes(fill = NMLG)) +
  geom_rug() +
  geom_vline(aes(xintercept = rbarDcc)) +
  facet_wrap(~pop, ncol  = 1)
  
```

What it's showing is that when the number of MLGs are reduced to 3, the value
of $\bar{r}_d$ can be really negative! 

Now back to the show. 


```{r, fig.width = 10, fig.height = 7}
bvals %>%
  ggplot(aes(x = p.rDcc, group = mutation_rate, fill = mutation_rate)) +
  geom_density(alpha = 0.75) +
  geom_rug(alpha = 0.5) +
  facet_grid(sexrate~sample, scales = "free_y") +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  ggtitle("Clone-censored p-values without bias correction") +
  xlab("P-value")


bvals %>%
  ggplot(aes(x = jack.p.rDb, group = mutation_rate, fill = mutation_rate)) +
  geom_density(alpha = 0.75) +
  geom_rug(alpha = 0.5) +
  facet_grid(sexrate~sample, scales = "free_y") +
  scale_fill_viridis(option = "D", discrete = TRUE) +
  ggtitle("P-values after bias correction of clone-censored data") +
  xlab("P-value (bias-corrected)")


bvals %>%
  unite(the_group, seed, rep, run, gen) %>%
  ggplot(aes(x = sexrate, y = bias, fill = mutation_rate)) +
  geom_line(aes(group = the_group), alpha = 0.2) +
  geom_boxplot(aes(group = factor(sexrate))) +
  # geom_point(aes(group = the_group), alpha = 0.2) +
  facet_grid(sample ~ mutation_rate) +
  ggtitle("Progression of bias", subtitle = "full data set compared to sub-sample")
```

## Flaws with "bias correction"

After thinking about this for a little bit, I realized that this method is
flawed because the bias is greater if the clone-corrected data is closer to
zero. An example can be shown with the "nancycats" data set in *adegenet*,
documenting 17 colonies of cats in Nancy, France. Since we know cats don't
clone, we can trust that this data set comes from sexual organisms.

```{r}
data("nancycats")
nan7 <- nancycats[pop = 7]
set.seed(999)
nan72 <- nan7[sample(nInd(nan7), nInd(nan7)*2, replace = TRUE)]
indNames(nan72) <- paste("sample", seq(nInd(nan72)))
nan72 <- as.genclone(nan72)
nan7ia    <- ia(nan7, sample = 999, valuereturn = TRUE, quiet = TRUE, plot = FALSE)
nan72ia   <- ia(nan72, sample = 999, valuereturn = TRUE, quiet = TRUE, plot = FALSE)
nan72ccia <- ia(clonecorrect(nan72, NA), sample = 999, valuereturn = TRUE, quiet = TRUE, plot = FALSE)
nanjack   <- jack.ia(nan72, use_psex = TRUE, method = 'multiple', mul = 2, rep = 999, quiet = TRUE)
idx       <- c("Ia", "rbarD")
nan72bi   <- nan72ccia
# Calculating the bias-correction
nan72bi$index[idx] <- nan72ccia$index[idx] - map2_dbl(nanjack, nan72ia$index[idx], function(a, b) (mean(a) - b))
nan72bi$index[c(FALSE, TRUE)] <- map2_dbl(nan72bi$index[idx], nan72bi$samples, makep)
plot(nan7ia) + ggtitle("Original Data")
plot(nan72ia) + ggtitle(paste("Resampled Data with", nmll(nan72), "unique samples"))
plot(nan72ccia) + ggtitle(paste("Resampled Data (clone-corrected)"))
plot(nan72bi) + ggtitle(paste("Resampled Data (bias-corrected)"))
```

We would have declared this population incorrectly to be clonal, but if we
simply used the mean of the jack-knifed samples (accounting for $p_{sex}$), 
`r round(mean(nanjack$rbarD), 3)`, we would not have been able to reject it.


## Using resampling with $p_{sex}$ as an estimate

Here, we will use the mean of the jack-knifed samples as the estimate and
re-calculate the p-value from there. Note that we are using the null 
distribution generated from the full data set to 


```{r pvals-psex-jack, fig.height = 7, fig.width = 7}
jvals <- vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  mutate(jack.mean = map_dbl(jack.rd, mean, na.rm = TRUE)) %>%
  mutate(bias = jack.mean - rbarDcc) %>%
  mutate(jack.p = map2_dbl(jack.mean, samples.rd, makep)) %>%     # against the full null
  mutate(jack.pcc = map2_dbl(jack.mean, samples.rdcc, makep)) %>% # against the clone-corrected null
  select(jack.pcc, everything())
```

What I show here are the results when compared against the full null
distribution, which exhibits less variance than the clone-corrected null. *When
compared against the clone-corrected null, there were no cases where the null
hypothesis was rejected at the 0.01 level.*

There are three tables:

 - Using the mean of the resampled distribution at p &leq; 0.01
 - Same as above OR $E_{5A} \geq 0.85$
 - The p &leq; 0.01 AND $E_{5A} \geq 0.85$

```{r}
jvals %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sum(jack.p <= 0.01, na.rm = TRUE)/n()) %>%
  spread(sample, reject) %>%
  knitr::kable(digits = 3, caption = "Null Hypothesis Rejected (p <= 0.01)")
jvals %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sum(jack.p <= 0.01 | Evennesscc > 0.85, na.rm = TRUE)/n()) %>%
  spread(sample, reject) %>%
  knitr::kable(digits = 3, caption = "Null Hypothesis Rejected (p <= 0.01 or E5A > 0.85)")
jvals %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sum(jack.p <= 0.01 & Evennesscc > 0.85, na.rm = TRUE)/n()) %>%
  spread(sample, reject) %>%
  knitr::kable(digits = 3, caption = "Null Hypothesis Rejected (p <= 0.01 and E5A > 0.85)")
```




```{r}
jvals %>%
  ggplot(aes(x = jack.p, group = mutation_rate, fill = mutation_rate)) +
  geom_histogram(alpha = 0.5, binwidth = 0.05) +
  facet_grid(sexrate~sample, scales = "free") +
  ggtitle("P-value from jack-knife analysis weighted by psex")
```

I thought that maybe there might be some effect in bias where clonal samples 
would exhibit a greater bias, but this does not appear to be the case.

```{r}
jvals %>%
  unite(the_group, seed, rep, run, gen) %>%
  ggplot(aes(x = sexrate, y = bias, fill = mutation_rate)) +
  # geom_line(aes(group = the_group), alpha = 0.2) +
  geom_boxplot(aes(group = factor(sexrate))) +
  # geom_point(aes(group = the_group), alpha = 0.2) +
  facet_grid(sample ~ mutation_rate) +
  scale_y_log10() +
  ggtitle("Progression of bias", subtitle = "full data set compared to sub-sample")
```


# Conclusions

Clone-correction provides a means of assessing $\bar{r}_d$ without the bias from
duplicated genotypes (which tends to inflate the statistic) at the cost of bias
from a decreased sample size. It is intuitive that we can account for the sample
size bias by randomly sampling a subset of the data without replacement and
recalculating $\bar{r}_d$. The problem is that, while this removes the bias due
to sample size, it's still affected by the bias introduced from over-represented
genotypes.

We can address both of these biases at the same time by weighting the samples by
the probability of encountering the *n*th sample of the same genotype by chance,
also known as $p_{sex}$. This allows identical genotypes from different genets
to be included in the analysis and gives us a better idea of what the population
without identical-by-descent genotypes looks like.

An example of how this works can be seen in real data from the outbreak of
*Phytophthora ramorum* in Curry County, OR.


```{r, cc_example}
library("poppr")
data(Pram)
iard <- c("Ia", "rbarD") # vector to get stats from results
JHC <- Pram[pop = "JHallCr_OR"] # grabbing the Joe Hall Creek watershed
# calculating allele frequencies from entire epidemic
af  <- rraf(Pram, by_pop = FALSE, mul = 2, res = "vector")
jia   <- ia(JHC, sample = 999, quiet = TRUE, valuereturn = TRUE)
jiacc <- JHC %>% clonecorrect(NA) %>% ia(sample = 999, quiet = TRUE, valuereturn = TRUE)
jjak  <- jack.ia(JHC, quiet = TRUE, reps = 999, use_psex = TRUE, method = "multiple", freq = af)
(jbias <- map_dbl(jjak, mean, na.rm = TRUE))
(jiap  <- map2_dbl(jbias, jia$samples, function(a, b) (sum(a <= b, na.rm = TRUE) + 1)/(length(b) + 1)))
df <- data_frame(rbarD = c(jia$index[3], jiacc$index[3], jbias[2]),
                 type = c("observed", "clone-censored", "estimate"))
bind_rows(null = jia$samples,
          nullcc = jiacc$samples,
          resampled = jjak,
          .id = "type") %>%
  ggplot(aes(x = rbarD)) +
  geom_density(aes(fill = type), alpha = 0.5) +
  geom_rug(aes(color = type), alpha = 0.1) +
  geom_vline(xintercept = df$rbarD, lty = 1:3) +
  annotate(geom = "text", x = df$rbarD, y = 10*c(3, 5, 4), label = df$type, hjust = c(1.05, -0.05, -0.05)) +
  scale_fill_brewer(palette = "Set1", labels = c("Null", "Null (clone-censored)", "Resampled")) +
  scale_color_brewer(palette = "Set1", labels = c("Null", "Null (clone-censored)", "Resampled")) +
  # xlim(c(-0.06, 0.15)) +
  theme_bw(base_size = 14, base_family = "Helvetica")
```

What we can see from this example is that the estimate here would easily be
considered clonal when compared to the Full null distribution. However, when
compared to the clone-censored null, the estimate is still non-significant due
to the wide variance exhibited. Another issue arises when considering the fact
that this can only be performed on a small number of markers considering that
$p_{gen}$, and therefore $p_{sex}$ approaches zero as the number of loci 
increases. However, we can see that this approach does detect the non-random 
mating in populations with a sex rate >1%. 
