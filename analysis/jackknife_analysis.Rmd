---
title: "Assessing bias due to reduced sample size"
output:
  html_document: default
---

## Introduction

We've shown that clone-correction can reduce the power of $\bar{r}_d$ to detect
clonal reproduction, but it's also clear that a reduced sample size contributes
to this as well. To disentangle this, we assess the $\bar{r}_d$ from 1000 
replicates of *n* samples where *n* is the size of the data set after 
clone-correction. The data were processed via the `analyze_jackknife_ia.R`
script. These were saved in the `ma_jack_rda_files/` directory.


## Setup


### Packages

```{r, required_packages}
library('zksimanalysis')
```

### Loading Data

```{r}
res        <- load("../data/full_results.rda") # load original values of rd
jack_files <- list.files("../data/jack_rda_files/", full.names = TRUE) # load jackknife simulations
jacklist   <- setNames(jack_files, basename(jack_files))

for (i in jack_files){
  jacklist[basename(i)] <- load(i)
}
jackdat <- jacklist %>% 
  map_df(get, .id = "source") %>% 
  mutate(mutation_rate = ifelse(grepl("mutant", source), "even", "uneven")) %>%
  mutate(source = gsub("(^.+?feather).*$", "\\1.DATA.rda", source)) %>%
  select(matches("jack"), everything())
rm(list = jacklist)
gc()

# taking stock of how much data we have
jackdat %>% filter(!is.na(pop))
vals
```

Note that above, I'm filtering `jackdat` for non-missing populations. I should
explain this a bit. When `jack.ia` was put into *poppr*, the requirements for
running that **n** was greater than 2 and smaller than the total popualtion size.
If the number of MLGs did not fit this requirement, `tidy_jackia` would  return 
all `NA`, including that for population. 

We can't ask any questions regarding bias with missing data, so we are filtering
it out here.

```{r}
# combining original values and jackknife simulations
vals <- get(res) %>%
  inner_join(filter(jackdat, !is.na(pop)), # filtering out missing data
             by = c("source", "mutation_rate", "pop")) %>%
  select(rbarD, jack.rd, jack.p.rD, mutation_rate, everything())
vals
even_mutation   <- vals %>% filter(mutation_rate == "even")
uneven_mutation <- vals %>% filter(mutation_rate == "uneven")
```

## Data Exploring!

First, let's see what we have after the filtering:

```{r}
vals %>%
  group_by(mutation_rate, sexrate, sample) %>%
  summarize(n = n()) %>%
  spread(sample, n) %>%
  knitr::kable()
```

Now, let's visualize the "p-value" for each jack knife analysis. This p-value
represents the fraction of jack-knife simulations less than or equal to the 
clone-corrected value. 

In essence, we are asking the following question:

> Can the clone-corrected value of $\bar{r}_d$ be attributed to a small sample
> size?

```{r pval, fig.width = 7, fig.height = 10}
vals %>%
  ggplot(aes(x = jack.p.rD, group = mutation_rate, fill = mutation_rate)) +
  geom_histogram(alpha = 0.5, binwidth = 0.05) +
  facet_grid(sexrate~sample, scales = "free")
```

Let's take a look at the values when the pvalue for $\bar{r}_d$ is < 0.05:

```{r pval-sig, fig.width = 7, fig.height = 7}
vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sprintf("%.2f (%d)", sum(jack.p.rD < 0.05)/n(), n())) %>%
  spread(sample, reject)
vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  ggplot(aes(x = jack.p.rD, group = mutation_rate, fill = mutation_rate)) +
  geom_histogram(alpha = 0.5, binwidth = 0.05) +
  facet_grid(sexrate~sample, scales = "free_y")
```

Yeah, those don't look too good. The graph above is basically saying that we
would consider most of the clonal populations to be sexually derived because the
clone-corrected value is lower than the distribution. Of course, this is 
expecting that the mean value for the distribution is near the observed value of
the whole data set. This may not be true.

To correct for this, I'm going to calculate the bias a la Section 10.3 in Efron 
and Tibshirani by subtracting the observed value from the bootstrap estimate:

$$
\hat\theta_B = \frac{1}{B} \sum\theta^*\\
Bias[\hat\theta] = \hat\theta_B - \hat\theta
$$

Once I have the bias, I'm going to compare the bias-corrected value of the
clone-corrected $\bar{r}_d$ to the null distribution of the full data set. This
would allow us to see if the reduced sample size affected the data (good example
from <http://www.stat.umn.edu/geyer/5601/examp/bias.html>).


> Note to future Zhian:
> 
> The answer may not be as simple as accounting for bias due to sample size, but
> also bias due to duplicated samples. Perhaps the way to go is to subtract the
> sum of the biases from the data. 

```{r pvals-bias, fig.height = 7, fig.width = 7}
makep <- function(x, y) (sum(x <= y, na.rm = TRUE) + 1)/(length(y) + 1)
bvals <- vals %>%
  filter(p.rD < p.rDcc, p.rDcc > 0.05) %>%
  mutate(jack.mean = map_dbl(jack.rd, mean, na.rm = TRUE)) %>%
  mutate(bias = jack.mean - rbarD) %>% # calculating bias a la Effron
  select(bias, jack.mean, everything()) %>%
  mutate(jack.p.rDb = map2_dbl(rbarDcc - bias, samples.rd, makep)) %>%
  select(bias, jack.p.rD, jack.p.rDb, everything())
```

Now we can visualize this as a table of the percentage rejection.

```{r}
bvals %>%
  group_by(sexrate, sample) %>%
  summarize(reject = sprintf("%.2f (%.4f)", 
                             sum(jack.p.rDb < 0.05)/n(), 
                             median(bias, na.rm = TRUE))) %>%
  spread(sample, reject) %>%
  knitr::kable(digits = 3, caption = "Null Hypothesis Rejected (median bias)")
```


```{r, fig.width = 10, fig.height = 7}
bvals %>%
  ggplot(aes(x = p.rDcc, group = mutation_rate, fill = mutation_rate)) +
  geom_density(alpha = 0.75) +
  geom_rug(alpha = 0.5) +
  facet_grid(sexrate~sample, scales = "free_y") +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  ggtitle("Clone-censored p-values without bias correction") +
  xlab("P-value")


bvals %>%
  ggplot(aes(x = jack.p.rDb, group = mutation_rate, fill = mutation_rate)) +
  geom_density(alpha = 0.75) +
  geom_rug(alpha = 0.5) +
  facet_grid(sexrate~sample, scales = "free_y") +
  scale_fill_viridis(option = "D", discrete = TRUE) +
  ggtitle("P-values after bias correction of clone-censored data") +
  xlab("P-value (bias-corrected)")


bvals %>%
  unite(the_group, seed, rep, run, gen) %>%
  ggplot(aes(x = sexrate, y = bias, fill = mutation_rate)) +
  geom_line(aes(group = the_group), alpha = 0.2) +
  geom_boxplot(aes(group = factor(sexrate))) +
  # geom_point(aes(group = the_group), alpha = 0.2) +
  facet_grid(sample ~ mutation_rate)
```

# Conclusions

Clone-correction provides a means of assessing $\bar{r}_d$ without the bias from
duplicated genotypes (which tends to inflate the statistic) at the cost of bias
from a decreased sample size. By sub-sampling our data to the number of samples
equal to the clone-corrected size, we can obtain a distribution from which we
can calculate this bias and further use this to correct our clone-corrected
estimate. We can then use this corrected estimate to calculate a p-value from
the distribution derived from the full data set. 

It's clear, however that this is not a one-size-fits-all situation. Indeed, 
some values are rescued, about half fail to reject the null hypothesis of 
random mating. We can ask the queston of whether or not the clone-corrected data
is within the realm of values from jack-knifed samples, but it's clear from 
above that most of the samples from the jack-knife analysis are biased.
